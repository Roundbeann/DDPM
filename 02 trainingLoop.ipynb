{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-09T08:48:33.930536900Z",
     "start_time": "2024-03-09T08:48:32.922968500Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser # 参数转换？\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import einops # gif visualization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam #优化器\n",
    "from torch.utils.data import DataLoader # 数据迭代器\n",
    "\n",
    "from torchvision.transforms import Compose,ToTensor,Lambda\n",
    "from torchvision.datasets.mnist import MNIST, FashionMNIST #导入MNIST, FashionMNIST 两个数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fashion = True # 代表选用 FashionMNIST 数据集 \n",
    "train_flag = True # 代表训练模式，否则进行推理和生成\n",
    "\n",
    "# 定义DDPM类\n",
    "class MyDDPM():\n",
    "    pass\n",
    "\n",
    "# 定义Unet网络\n",
    "class MyUNet():\n",
    "    pass\n",
    "\n",
    "# 展示图片\n",
    "def show_images():\n",
    "    pass\n",
    "\n",
    "# 生成图片（采样过程）\n",
    "def generate_new_images():\n",
    "    pass\n",
    "\n",
    "# 加噪的步长\n",
    "n_steps = 100\n",
    "\n",
    "# 实例化DDPM类\n",
    "ddpm = MyDDPM()\n",
    "# ddpm = MyDDPM(MyUNet(), n_steps = n_steps, device = device)\n",
    "\n",
    "loader = None\n",
    "n_epochs = None\n",
    "optim = None\n",
    "device = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7197585326b58a92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ee4f1c7151148bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 选用FashionMnist 模型存储路径则为 “ddpm_fashion.pt”\n",
    "store_path = \"ddpm_fashion.pt\" if fashion else \"ddpm_mnist.pt\" # 定义模型的存储路径\n",
    "\n",
    "def training_loop(ddpm, loader, n_epochs, optim, device, display = False, store_path = \"ddpm_model.pt\"):\n",
    "    # 定义均方误差损失\n",
    "    mse = nn.MSELoss()\n",
    "    # 初始化loss为+∞ 不断更新得到最小的loss 最优的model\n",
    "    best_loss = float(\"inf\") \n",
    "    # t = 0, 1, 2, 3,...,1000 这些t是DDPM()的属性\n",
    "    n_steps = ddpm.n_steps\n",
    "    \n",
    "    # 遍历每一个epoch\n",
    "    for epoch in tqdm(range(n_epochs), decs = f\"Training progress\", colour=\"#00ff00\"):\n",
    "        epoch_loss = 0.0\n",
    "        # leave = False 进度条跑完一次后不会保留在终端上面，而是会开始下一次的进度展示 \n",
    "        \n",
    "        # 遍历一个epoch下的多个batch_size(由data_loader迭代返回每个batch_size的数据)\n",
    "        # 一个batch当中有128张图片\n",
    "        for step,batch in enumerate(tqdm(loader, leave = False, desc = f\"Epoch {epoch + 1}/{n_epochs}\", colour = \"#005500\" )):\n",
    "            x0 = batch[0].to(device)   # x0 是一个batch(?)，x[0]当中包含128张【原图】\n",
    "            n = len(x0) # batchsize的大小\n",
    "            \n",
    "            t = None\n",
    "            eta = None\n",
    "            # DDPM 前向过程: 加噪声的过程\n",
    "            # 前向过程的eta是GT\n",
    "            # 前向过程输入原图、扩散步长、所家的\n",
    "            # 前向过程得到噪声图像\n",
    "            noisy_imgs = ddpm(x0,t,eta) # x0 [128, 1, 28, 28] x0是一批原图\n",
    "            \n",
    "            # DDPM 逆向过程: 对原图去噪的过程\n",
    "            # 逆向过程，用模型来预测噪声，和原来我们自己加的噪声进行对比\n",
    "            # eta_theta 就是 ddpm 模型反向传播预测得到的噪声 predicted noise\n",
    "            # 反向过程输入噪声图、前向扩散的步长\n",
    "            # 反向过程预测得到前向过程添加了多少噪声\n",
    "            eta_theta = ddpm.backward(noisy_imgs, t)\n",
    "            \n",
    "            # 对【GT也就是我们实际加的噪声】和【predicted noise也就是DDPM预测得到的噪声】做损失\n",
    "            loss = mse(eta, eta_theta)\n",
    "            \n",
    "            # 清零梯度\n",
    "            optim.zero_grad()             \n",
    "            \n",
    "            # loss反向传播\n",
    "            loss.backward()\n",
    "            \n",
    "            # 更新loss (随机梯度下降法？求导更新权重)\n",
    "            optim.step()\n",
    "            \n",
    "            # 平均损失\n",
    "            epoch_loss += loss.item() * len(x0) / len(loader.dataset)\n",
    "            \n",
    "        # 跑完一个epoch之后，用我们得到的模型去生成一张图像并展示\n",
    "        if display:\n",
    "            # 每轮输出：在第i轮生成的图像为{}\n",
    "            show_images(generate_new_images(ddpm,device = device), f\"Images generated at epoch{epoch + 1}\")\n",
    "        \n",
    "        # 日志记录本轮的损失\n",
    "        log_string = f\"Loss at epoch {epoch + 1}: {epoch_loss:.3f}\"\n",
    "        \n",
    "        # 保存效果更好的模型\n",
    "        if best_loss > epoch_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(ddpm.state_dict(),store_path)\n",
    "            log_string += \" --> Best model ever(stored)\"\n",
    "        \n",
    "\n",
    "if train_flag: # 训练模式下执行训练\n",
    "    training_loop(ddpm, loader, n_epochs, optim, device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c61f2994d59331e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing and Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c448af7b93190fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "best_model = MyDDPM(MyUNet(), n_steps = n_steps, device = device) \n",
    "# 加载权重参数/模型到 device\n",
    "best_model.load_state_dict(torch.load(store_path), map_location = device) \n",
    "# 开启评估模式/推理模式\n",
    "best_model.eval() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53d146472e1b4727"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 采样器\n",
    "# 输入：预测杂声的模型，加噪步长，图片生成过程\n",
    "generated = generate_new_images(\n",
    "    best_model,\n",
    "    n_samples = 100,\n",
    "    device = device,\n",
    "    gif_name = \"fashion.gif\" if fashion else \"mnist.gif\"\n",
    ")\n",
    "\n",
    "show_images(generated, \"Final result\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8a91f15ee617dfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
